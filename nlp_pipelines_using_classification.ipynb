{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO2lMMAXn2lv",
        "outputId": "02651f10-bac2-44fb-ffba-dbe524e19512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Complet   NLP_Pipelines to creat data\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import re\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove special characters and numbers\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Remove stopwords and lemmatize\n",
        "        tokens = [self.lemmatizer.lemmatize(token)\n",
        "                 for token in tokens\n",
        "                 if token not in self.stop_words]\n",
        "\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "class NLPPipeline:\n",
        "    def __init__(self, max_features=5000):\n",
        "        self.preprocessor = TextPreprocessor()\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=max_features,\n",
        "            ngram_range=(1, 2)  # Include unigrams and bigrams\n",
        "        )\n",
        "\n",
        "        # Initialize different models\n",
        "        self.models = {\n",
        "            'naive_bayes': MultinomialNB(),\n",
        "            'logistic_regression': LogisticRegression(max_iter=1000),\n",
        "            'svm': LinearSVC(max_iter=1000)\n",
        "        }\n",
        "\n",
        "    def prepare_data(self, texts, labels):\n",
        "        # Preprocess all texts\n",
        "        processed_texts = [self.preprocessor.preprocess(text) for text in texts]\n",
        "\n",
        "        # Create TF-IDF features\n",
        "        X = self.vectorizer.fit_transform(processed_texts)\n",
        "\n",
        "        # Split data\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X, labels, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "    def train_and_evaluate(self):\n",
        "        results = {}\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            # Train model\n",
        "            model.fit(self.X_train, self.y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = model.predict(self.X_test)\n",
        "\n",
        "            # Calculate metrics\n",
        "            results[name] = {\n",
        "                'classification_report': classification_report(self.y_test, y_pred),\n",
        "                'confusion_matrix': confusion_matrix(self.y_test, y_pred)\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict_new(self, texts):\n",
        "        # Preprocess new texts\n",
        "        processed_texts = [self.preprocessor.preprocess(text) for text in texts]\n",
        "\n",
        "        # Transform to TF-IDF features\n",
        "        X_new = self.vectorizer.transform(processed_texts)\n",
        "\n",
        "        # Make predictions with each model\n",
        "        predictions = {}\n",
        "        for name, model in self.models.items():\n",
        "            predictions[name] = model.predict(X_new)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample data (replace with your actual dataset)\n",
        "    texts = [\n",
        "        \"This movie is memorable \",\n",
        "        \"You also hurt me and disappointed\",\n",
        "        \" I hate you\",\n",
        "        \"This movie was fantastic! I loved every minute of it.\",\n",
        "        \"Terrible waste of time. Worst movie ever.\",\n",
        "        \"Great acting, but the plot was weak.\",\n",
        "        # ... add more examples\n",
        "    ]\n",
        "\n",
        "    labels = [1, 0, 0, 1, 0, 1]  # 1 for positive, 0 for negative\n",
        "\n",
        "    # Create and run pipeline\n",
        "    pipeline = NLPPipeline(max_features=3000)\n",
        "\n",
        "    # Prepare data\n",
        "    pipeline.prepare_data(texts, labels)\n",
        "\n",
        "    # Train and evaluate models\n",
        "    results = pipeline.train_and_evaluate()\n",
        "\n",
        "    # Print results\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"\\nResults for {model_name}:\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(metrics['classification_report'])\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(metrics['confusion_matrix'])\n",
        "\n",
        "    # Example of predicting new texts\n",
        "    new_texts = [\n",
        "        \"I really enjoyed this movie!\",\n",
        "        \"This was a complete disappointment.\"\n",
        "    ]\n",
        "\n",
        "    predictions = pipeline.predict_new(new_texts)\n",
        "    for model_name, preds in predictions.items():\n",
        "        print(f\"\\nPredictions from {model_name}:\")\n",
        "        for text, pred in zip(new_texts, preds):\n",
        "            print(f\"Text: {text}\")\n",
        "            print(f\"Prediction: {'Positive' if pred == 1 else 'Negative'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vghGHctDuG5L",
        "outputId": "a9c9b149-9136-4d90-f19a-b4e380bff0fe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for naive_bayes:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0]\n",
            " [1 0]]\n",
            "\n",
            "Results for logistic_regression:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "\n",
            "Results for svm:\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 1]\n",
            " [0 1]]\n",
            "\n",
            "Predictions from naive_bayes:\n",
            "Text: I really enjoyed this movie!\n",
            "Prediction: Negative\n",
            "Text: This was a complete disappointment.\n",
            "Prediction: Negative\n",
            "\n",
            "Predictions from logistic_regression:\n",
            "Text: I really enjoyed this movie!\n",
            "Prediction: Positive\n",
            "Text: This was a complete disappointment.\n",
            "Prediction: Positive\n",
            "\n",
            "Predictions from svm:\n",
            "Text: I really enjoyed this movie!\n",
            "Prediction: Positive\n",
            "Text: This was a complete disappointment.\n",
            "Prediction: Positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ruRfrE5Ct8S8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}